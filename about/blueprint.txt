
Overview
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

major steps to deciphering PNG image
	1. dechunking
	2. decompressing
	3. defiltering
	4. de-scanline-ing
	5. (potentially) de-interlacing


Dechunking
==================================================

reading image context data, like how it is formatted or its dimensions
PNGs split data into chunks. IDAT chunks contain the compressed data, potentially split btwn multiple chunks


Decompressing
==================================================

Compression method 0 is the only standardized allowed method. It is using ZLIB compression method 8, which uses DEFLATE.


Defiltering
==================================================

filter method 0 is the only alloewd method.

Each scanline is prefixed by an identifier for 1 of five "filter types" within filter method 0.
	0: none
	1: sub
	2: up
	3: average
	4: paeth

filter functions apply to bytes, not pixels.
the filtering functions are concerned with 4 diffent bytes:
	- 'x': the current byte being filtered
	- 'a': the byte ~~preceding~~ x (before 'a' was filtered)
	- 'b': the byte *above* x, aka in the previous scanline, (before 'b' was filtered)
	- 'c': 'a' of 'b', before 'c' was filtered
	if any of these bytes are out of the bounds of the sequence, eg first byte of a scanline or first scanline, they are equal to 0

	NOTE: the preceding byte is NOT NECESSARILY the immediately prior byte!!!
		it is the byte corresponding to x in the previous pixel, not the previous byte
		UNLESS bitdepth < 8, in which case it is just the previous byte


de-scanline-ing
==================================================

pixels in scanlines are packed without wasting bits between each other.
scanlines themselves always start on a byte boundary, though
	the bits between these gaps need not be 0. They can be anything.
scanlines are all the same length

when sub-byte pixels, the leftmost (first) sample starts in the high-order bits of the byte
	sub-byte samples are not permitted combinations
when multi-byte pixels/samples, its MSB byte first


sizing notes
==================================================

scanlines are at most 2^31 pixels long
	^ accounting for scanline trailing bits, since there are no trailing bits for bitDepth > 8
images are at most 2^31 scanlines tall
pixels are at most 8B long
uint64_t can represent a byte index throughout the largest possible image

uint64_t cannot represent abit index, however





PNG Anatomy
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

(multi-byte values are big-endian)

8B PNG Header:
	0x89
	'P'
	'N'
	'G'
	0x0D
	0x0A
	0x1A
	0x0A
IHDR Chunk : Image Header
	4B length: 13
	4B type: 'I', 'H', 'D', 'R'
	[length]B data:
		4B width
			!0
		4B height
			!0
		1B bitDepth
			generally: 1, 2, 4, 8, 16

			represents bits per SAMPLE (not per pixel)
				so, if rgba & '8', is rgba=4 * 8 = 32 bits per pixel

			only certain values are valid with color types:
				colourType : bitDepth
				0	: 1,2,4,8,16
				3	: 1,2,4,8
				2,4,6	: 8,16

		1B colourType
			0, 2, 3, 4, 6
				greyscale
				truecolor
				indexed-color
				greyscale alpha
				truecolor alpha
		1B compressionMethod = 0
		1B filterMethod = 0
		1B interlaceMethod
			0, 1 : none, Adam7
	4B CRC
	
n Chunks
	Chunk:
		4B length
			< 80_00_00_00
		4B type
			4 1-byte chars
				only a-z or A-Z

			capitalization encodes meaning
				B[0]
					uppercase = CRITICAL
					lowercase = ANCILLARY
				B[1]
					uppercase = PUBLIC CHUNK
					lowercase = PRIVATE CHUNK

					public is defined by official PNG standards, private is specific to some environment
				B[2]
					uppercase = ACCEPTABLE
					lowercase = RESERVED: ERROR
				B[3]
					upparcase = NOT SAFE TO COPY
					lowercase = SAFE TO COPY
						
					irrelevant for decoders
					? whether the chunk can be copied by a PNG editor if its unrecognized to the new PNG ?

			"capitalization" is defined by checking the corresponding ASCII capitalization bit, not by checking the actual letter ranges.
				1 = lowercase, 0 = uppercase / as per ascii

		[length]B data
		
		4B CRC Cyclic Redundancy Code
			calculated over "type" & "data"
			to check for corruption of the data

	Chunk Ordering:
		I am only mentioning the CRITICAL chunks here

		IHDR:
			only 1
			always FIRST
			(see above)
		PLTE:
			only 1
			appears before IDAT
		IDAT:
			multiple allowed
			appear consecutively
		IEND:
			only 1
			always LAST
			(see below)
IEND Chunk
	4B length: 0
	4B type: IHDR
	[length]B data
	4B CRC


IDAT
==================================================

data within idats, when appended together, is a zlib-compressed stream

PLTE
==================================================



Zlib
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

2B zlib header
	1B CMF
		4b compression method = 8 (for PNGs)
		4b additional info, depedning on prev 4 bits
			when compression method == 8:
				is log2(lz77_window_size - 8)
				CANNOT be > 7
	 FLG flags
		5b validation value
			ensures that these 2 bytes, as a 16bit uint, MSB being CMF, is divisible by 31 (x % 31 = 0)
		1b FDICT = 0 (for PNGs)
			if 1, indicates presence of a preset dict
		2b FLEVEL
			the level of compression the compressor used

			irrelevant for decompressors
0|4B DICT
	(only present if FDICT flag bit == 1)
	never present for PNGs
	identifies the preset dict that was used in compression
	is an ADLER32 of the dict

(n)B data
	a stream of data following the DEFLATE format

4B ADLER32
	checksum of decompressed data, to ensure decompression was correct


DEFLATE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

consists of a series of blocks:

3b block header
	1b isLastBlock
	2b compressionType
		00 = uncompressed
		01 = fixed
		10 = dynamic
		11 = reserved, error
(corresponding data sequence to compressionType)


uncompressed
==================================================

(LSB to MSB)

* uncompressed data always starts byte-aligned

2B length
2B 1s complement of length, for validataion

[length]B raw bytes of data


fixed
==================================================

(n) fixedTreeCodes
1 fixedTreeCode 256 "end of block"


dynamic
==================================================

5b num_literal_codeLengths
5b num_distance_codeLengths
4b num_meta_codeLengths

(num_meta_codelengths + 4) * 3 bits
	int3s corresponding to metaTree codeLengths
	given in metaTree's special sorted order
num_literal_codeLengths + 257 metaTreeCodes
num_distance_codeLengths + 1 distanceTreeCodes

(n) dynamicTreeCodes
1 dynamicTreeCode 256 "end of block"


Tree Representation Options
==================================================

defining the trees
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

fixed tree:
	tree created for the fixed-huffman-codes compression method

~~fixed-distance tree:~~
	unnecessary because fixed distance codes are just 5-bit ints


meta tree:
	tree created to decode the sequence of codeLengths which define the dynamic tree

dynamic tree:
	tree created to decode data in dynamic-huffman-codes compression method

distance tree:
	tree to decode distance codes in dynamic-huffman-codes compression method


tree rules
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

fixed tree
--------------------------------------------------
codeLength_min = 7
codeLength_max = 9
num_unique_values = 288 // 0 through 287

fixed tree has, well, fixed structure
take from the DEFLATE specification:
	Lit Value          Bits        Codes
	---------          ----        -----
	  0 through 143     8          00110000 through 10111111
	144 through 255     9          110010000 through 111111111
	256 through 279     7          0000000 through 0010111
	280 through 287     8          11000000 through 11000111


meta tree
--------------------------------------------------
codeLength_min = 1
codeLength_max = 7 // meta codeLengths are given as int3s
num_unique_values = 19 // 0 through 18

values are sorted in this order:
	16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15
	
	this is relevant for deciphering the codes when decoding, AND for !{something else I cant remember}!

dynamic tree
--------------------------------------------------
codeLength_min = 1
codeLength_max = 15 // higher codes cannot be represented in the meta tree
num_unique_values = 288 // 0 through 287


distance tree
--------------------------------------------------
codeLength_min = 1
codeLength_max = 15 // capped for same reason as dynamic tree
num_unique_values = 30 // 0 through 29


representations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

these are some general ways to represent the trees in memory/code
this doesnt include combinations of these methods
im sure there are more yk

it comes down to prioritizing performance vs memory footprint
	considering the images themselves end up being loaded into memory, uncompressed ...


num_unique_codeLengths = codeLength_max - codeLength_min + 1


instant
--------------------------------------------------

lookup: O(1)

entries: 2^(codeLength_max)
entry bits:
	ceilLog2(num_unique_values) + ceilLog2(num_unique_codeLengths)

- fixedTree:	512entries * (9 + 2)
- metaTree:	128entries * (5 + 3)
- dynamicTree:	32k * (9 + 4)
- distanceTree:	32k * (5 + 4)

entries are stored so that a (codeLength_max)-int-index can directly locate the corresponding entry.
	detailed here: [https://www.infinitepartitions.com/art001.html]

Honestly, is probably worth it to go this route since the images will be loaded into memory uncompressed anyways.
I mean, the difference between O(1) and anything else is infinite.
But, the way that the codes overdraw bits to get the indexes complicates everything a bit.
	I'm going to start off by trying some of the other methods, but maybe return to this later.


unbalanced binary tree
--------------------------------------------------

lookup: O(log n)

entries: num_unique_values - 1
entry bits:
	~~{
	ceilLog2(num_unique_values) + 2) * 2
	OR
	(ceilLog2(num_unique_values + 1) + 1) * 2
	}~~

	(ceilLog2(num_unique_values) + 1) * 2
		prev was thinking that needed to represent 1 more value as NULL. NULL can be ROOT though.

~~{
- fixedTree:	287entries *  ( 11 or 10 ) * 2		5740b -> 718B	|or	861B
- metaTree:	18entries *  ( 7 or 6 ) * 2		 216b -> 27B	|or	36B
- dynamicTree:	287entries *  ( 11 or 10 ) * 2		5740b -> 718B	|or	861B
- distanceTree:	29entries * ( 7 or 6 ) * 2		 348b -> 44B	|or	58B
}~~

- fixedTree:	287entries * 10 * 2		5740b -> 718B	|or	861B
- metaTree:	18entries * 6 * 2		 216b -> 27B	|or	36B
- dynamicTree:	287entries * 10 * 2		5740b -> 718B	|or	861B
- distanceTree:	29entries * 6 * 2		 348b -> 44B	|or	58B

entries are stored as nodes in a binary tree. their L/R values can be NULL, VALUE, or NODEIDX
	one method encodes NULL as a unique L/R value, other encodes NULL as a separate bit


linear per code
--------------------------------------------------

lookup: O(n) each code

entries: num_unique_values
entry bits:
	ceilLog2(num_unique_values) + ceilLog2(num_unique_codeLengths)

- fixedTree:	288entries * (9 + 2)		3168b -> 396B
- metaTree:	19 * (5 + 3)			 152b -> 19B
- dynamicTree:	288entries * (9 + 4)		3744b -> 48B
- distanceTree:	30 * (5 + 4)			 270b -> 34B

entries are sorted based on their codelengths, so only have to go through the list once per code


linear per bit
--------------------------------------------------

lookup: O(n) each bit of a code

entries: num_unique_values
entry bits:
	ceilLog2(num_unique_codeLengths)

- fixedTree:	288entries * 2 		464b -> 58B
- metaTree:	19 * 3			 42b -> 6B
- dynamicTree:	288entries * 4		928b -> 116B
- distanceTree:	30 * 4			120b -> 15B

entries are sorted where their index == their corresponding value. Saves space but have to scan entire list each bit of a code.


honourable mentions
--------------------------------------------------

balanced binary tree
	basically as much space as instant, but 0(n). Totally wasnt one of the first things I thought of.
